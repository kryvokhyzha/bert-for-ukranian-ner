{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tokenize_uk\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(filename: Path) -> Dict:\n",
    "    with open(filename, 'r') as file:\n",
    "        config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH2ROOT = Path('..')\n",
    "PATH2CONFIG = Path(PATH2ROOT / 'configs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = get_config(PATH2CONFIG / 'config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH2COURPUS = Path(PATH2ROOT / CONFIG['data']['path_to_corpus_folder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATION = string.punctuation + '«' + '»' + '–'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames() -> Dict[str, Dict[str, str]]:\n",
    "    result = dict()\n",
    "    for filename in os.listdir(PATH2COURPUS):\n",
    "        file_tokenize = filename.split('.')\n",
    "\n",
    "        if file_tokenize[-2] != 'tok':\n",
    "            continue\n",
    "        elif file_tokenize[-1] == 'ann':\n",
    "            t = ' '.join(file_tokenize[:-2])\n",
    "            if t in result:\n",
    "                result[t]['ann'] = filename\n",
    "            else:\n",
    "                result[t] = {'ann': filename}\n",
    "            pass\n",
    "        elif file_tokenize[-1] == 'txt':\n",
    "            t = ' '.join(file_tokenize[:-2])\n",
    "            if t in result:\n",
    "                result[t]['txt'] = filename\n",
    "            else:\n",
    "                result[t] = {'txt': filename}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_annotation(annotation: str) -> List[str]:\n",
    "    types_dict = {\n",
    "        'ПЕРС': 'PERS',\n",
    "        'ЛОК': 'LOC',\n",
    "        'ОРГ': 'ORG',\n",
    "        'РІЗН': 'MISC',\n",
    "        'PERS': 'PERS',\n",
    "        'LOC': 'LOC',\n",
    "        'ORG': 'ORG',\n",
    "        'MISC': 'MISC',\n",
    "    }\n",
    "    ann_list = annotation.split('\\t')\n",
    "\n",
    "    type_annotation = types_dict[ann_list[1].split(' ')[0]]\n",
    "    tokens = tokenize_uk.tokenize_words(ann_list[2])\n",
    "    return list(map(lambda x: (x, f'{type_annotation}'), tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_text_to_parallel() -> pd.DataFrame:\n",
    "    df = pd.DataFrame()\n",
    "    for filename, paths in tqdm(get_filenames().items()):\n",
    "        with open(PATH2COURPUS / paths['txt'], 'r') as file:\n",
    "            txt = file.read()\n",
    "\n",
    "        with open(PATH2COURPUS / paths['ann'], 'r') as file:\n",
    "            ann = file.read()\n",
    "\n",
    "        tokens = list()\n",
    "        list(\n",
    "            map(\n",
    "                lambda x: tokens.extend(process_annotation(x)) if x else x,\n",
    "                ann.split('\\n'),\n",
    "            )\n",
    "        )\n",
    "        txt = map(\n",
    "            lambda sentence: tokenize_uk.tokenize_words(sentence),\n",
    "            tokenize_uk.tokenize_sents(' '.join(tokenize_uk.tokenize_words(txt))),\n",
    "        )\n",
    "\n",
    "        for sentence in txt:\n",
    "            words = []\n",
    "            tags = []\n",
    "            for word in sentence:\n",
    "                if tokens and word == tokens[0][0]:\n",
    "                    word, tag = tokens.pop(0)\n",
    "                    words.append(word)\n",
    "                    tags.append(tag)\n",
    "                else:\n",
    "                    words.append(word)\n",
    "                    tags.append('O')\n",
    "\n",
    "            df = df.append([{'filename': filename, 'text': words, 'tags': tags}])\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [00:17<00:00, 15.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# result = raw_text_to_tabular()\n",
    "result = raw_text_to_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_Halytskyi_korespondent_Fedoliak_Baseyn_peret...</td>\n",
       "      <td>[Не, встигла, новостворена, П’ядицька, ОТГ, за...</td>\n",
       "      <td>[O, O, O, LOC, LOC, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_Halytskyi_korespondent_Fedoliak_Baseyn_peret...</td>\n",
       "      <td>[Як, наслідок, ,, на, коломийському, стадіоні,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, ORG, O, O, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_Halytskyi_korespondent_Fedoliak_Baseyn_peret...</td>\n",
       "      <td>[Турці, .]</td>\n",
       "      <td>[LOC, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_Halytskyi_korespondent_Fedoliak_Baseyn_peret...</td>\n",
       "      <td>[Мовляв, ,, тренерам, повідомили, про, звільне...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_Halytskyi_korespondent_Fedoliak_Baseyn_peret...</td>\n",
       "      <td>[Присутні, створили, ініціативну, групу, ,, об...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12009</th>\n",
       "      <td>I_Ivanychuk_1_Torhovytsia_2013(5)</td>\n",
       "      <td>[На, початку, Личаківської, звернув, у, Круняр...</td>\n",
       "      <td>[O, O, LOC, O, O, LOC, LOC, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12010</th>\n",
       "      <td>I_Ivanychuk_1_Torhovytsia_2013(5)</td>\n",
       "      <td>[Юрків, родич, ,, член, ОУН, ,, день, відо, дн...</td>\n",
       "      <td>[PERS, O, O, O, ORG, O, O, O, O, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12011</th>\n",
       "      <td>I_Ivanychuk_1_Torhovytsia_2013(5)</td>\n",
       "      <td>[Примістив, його, в, потаємній, комірці, ,, де...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12012</th>\n",
       "      <td>I_Ivanychuk_1_Torhovytsia_2013(5)</td>\n",
       "      <td>[Професор, Сербин, приносив, щораз, тривожніші...</td>\n",
       "      <td>[O, PERS, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12013</th>\n",
       "      <td>I_Ivanychuk_1_Torhovytsia_2013(5)</td>\n",
       "      <td>[Мало, не, щодня, партприкріплені, до, міських...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                filename  \\\n",
       "0      A_Halytskyi_korespondent_Fedoliak_Baseyn_peret...   \n",
       "1      A_Halytskyi_korespondent_Fedoliak_Baseyn_peret...   \n",
       "2      A_Halytskyi_korespondent_Fedoliak_Baseyn_peret...   \n",
       "3      A_Halytskyi_korespondent_Fedoliak_Baseyn_peret...   \n",
       "4      A_Halytskyi_korespondent_Fedoliak_Baseyn_peret...   \n",
       "...                                                  ...   \n",
       "12009                  I_Ivanychuk_1_Torhovytsia_2013(5)   \n",
       "12010                  I_Ivanychuk_1_Torhovytsia_2013(5)   \n",
       "12011                  I_Ivanychuk_1_Torhovytsia_2013(5)   \n",
       "12012                  I_Ivanychuk_1_Torhovytsia_2013(5)   \n",
       "12013                  I_Ivanychuk_1_Torhovytsia_2013(5)   \n",
       "\n",
       "                                                    text  \\\n",
       "0      [Не, встигла, новостворена, П’ядицька, ОТГ, за...   \n",
       "1      [Як, наслідок, ,, на, коломийському, стадіоні,...   \n",
       "2                                             [Турці, .]   \n",
       "3      [Мовляв, ,, тренерам, повідомили, про, звільне...   \n",
       "4      [Присутні, створили, ініціативну, групу, ,, об...   \n",
       "...                                                  ...   \n",
       "12009  [На, початку, Личаківської, звернув, у, Круняр...   \n",
       "12010  [Юрків, родич, ,, член, ОУН, ,, день, відо, дн...   \n",
       "12011  [Примістив, його, в, потаємній, комірці, ,, де...   \n",
       "12012  [Професор, Сербин, приносив, щораз, тривожніші...   \n",
       "12013  [Мало, не, щодня, партприкріплені, до, міських...   \n",
       "\n",
       "                                                    tags  \n",
       "0      [O, O, O, LOC, LOC, O, O, O, O, O, O, O, O, O,...  \n",
       "1      [O, O, O, O, O, O, O, ORG, O, O, O, O, O, O, O...  \n",
       "2                                               [LOC, O]  \n",
       "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "...                                                  ...  \n",
       "12009  [O, O, LOC, O, O, LOC, LOC, O, O, O, O, O, O, ...  \n",
       "12010  [PERS, O, O, O, ORG, O, O, O, O, O, O, O, O, O...  \n",
       "12011  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "12012                           [O, PERS, O, O, O, O, O]  \n",
       "12013  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[12014 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Не',\n",
       " 'встигла',\n",
       " 'новостворена',\n",
       " 'П’ядицька',\n",
       " 'ОТГ',\n",
       " 'запрацювати',\n",
       " 'на',\n",
       " 'повну',\n",
       " 'силу',\n",
       " ',',\n",
       " 'як',\n",
       " 'вже',\n",
       " 'виникли',\n",
       " 'перші',\n",
       " 'проблеми',\n",
       " 'з',\n",
       " 'прийняттям',\n",
       " 'важливих',\n",
       " 'рішень',\n",
       " ',',\n",
       " 'йдеться',\n",
       " 'на',\n",
       " 'місцевих',\n",
       " 'інформаційних',\n",
       " 'ресурсах',\n",
       " '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.iloc[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/preproc-data/preproc-data.bin']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(result, PATH2ROOT / CONFIG['data']['path_to_preproc_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = joblib.load(PATH2ROOT / CONFIG['data']['path_to_preproc_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'LOC', 'LOC'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.iloc[1:2]['tags'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
